import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist

# Load the data
norm_data = pd.read_csv('wine.csv')

# Display the data and its shape
print(norm_data)
print(norm_data.shape)

# Perform PCA
pca = PCA()
pca_values = pca.fit_transform(norm_data)
print(pca_values.shape)

# Explained variance ratio
var = pca.explained_variance_ratio_
print(var)

# Cumulative explained variance
cum_var = np.cumsum(np.round(var, decimals=4) * 100)
print(cum_var)

# Create a DataFrame with PCA values and drop specified columns
pca_data = pd.DataFrame(pca_values)
pca_data = pca_data.drop(columns=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12])

# Range of values for k
k1 = list(range(2, 15))
TWSS1 = []

# Perform K-means clustering for different values of k
for i in k1:
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(pca_data)
    WSS1 = []

    # Calculate Within Sum of Squares for each cluster
    for j in range(i):
        WSS1.append(sum(cdist(pca_data.iloc[kmeans.labels_ == j, :], kmeans.cluster_centers_[j].reshape(1, pca_data.shape[1]), metric='euclidean')))
    
    # Append Total Within Sum of Squares for the current k
    TWSS1.append(sum(WSS1))

# Plot the Total Within Sum of Squares for different values of k
plt.plot(k1, TWSS1, 'bo-')
plt.xlabel('k value')
plt.ylabel('TWSS1')
plt.show()

# Fit K-means with k=4 (chosen from the plot) on PCA data
model1 = KMeans(n_clusters=4).fit(pca_data)
clusters_pca_k = pd.DataFrame(model1.labels_)

# Display the count of samples in each cluster
k_means_pca = clusters_pca_k.value_counts()
print(k_means_pca)

pca_data.shape
